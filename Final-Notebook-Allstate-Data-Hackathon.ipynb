{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Hackathon Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2016, GP practices in Northern Ireland wrote prescriptions for almost 29 million items. The number of items and their cost varied significantly, but using open data, we can help make predictions to aid budget planning.\n",
    "\n",
    "The goal of this competition is to build a predictive model with historical data to accurately predict the prescription costs of GP practices. We will be predicting the average prescription spend per patient for each GP practice, each month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is written in Python(3.5) on Ubuntu(16.04) and requires the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and Merging the Training Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* competition_starter.csv - the initial training set\n",
    "* competition_employment.csv - additional data with employment details\n",
    "* competition_waiting.csv - additional data with specialist waiting list time details\n",
    "* holdout.csv - the testing data to score your model on for submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The file path to the folder containing all the datasets.\n",
    "data_location = 'datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the starter dataset.\n",
    "file_name = 'competition_starter.csv'\n",
    "starter_data = pd.read_csv(data_location + file_name, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the employment dataset.\n",
    "file_name_employment = 'competition_employment.csv'\n",
    "employment_data = pd.read_csv(data_location + file_name_employment, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the starter and employment datasets based on the 'moa' column to form a new dataset.\n",
    "common_key = 'soa'\n",
    "hack_data = starter_data.merge(employment_data, on=common_key, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the waiting dataset.\n",
    "file_name_waiting = 'competition_waiting.csv'\n",
    "waiting_data = pd.read_csv(data_location + file_name_waiting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The newly created 'hack_data' dataset contains columns for 'gp_month' and 'gp_year'.\n",
    "# The waiting dataset on the otherhand contains the column 'quarter_end'.\n",
    "# The 'quarter_end' column can be easily broken up into 'gp_month' and 'gp_year'.\n",
    "waiting_data['gp_month'] = [int(i.split('-')[0]) for i in waiting_data['quarter_end']]\n",
    "waiting_data['gp_year'] = [int(i.split('-')[1]) for i in waiting_data['quarter_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The waiting dataset no longer requires the 'quarter_end' column. \n",
    "waiting_data = waiting_data.drop(['quarter_end'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the hack_data and waiting for datasets based now on the columns they share in common. \n",
    "common_key = ['hsc_trust', 'gp_month', 'gp_year']\n",
    "hack_data = hack_data.merge(waiting_data, on=common_key, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the health dataset.\n",
    "file_name_waiting = 'competition_health.csv'\n",
    "health_data = pd.read_csv(data_location + file_name_waiting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge the hack_data and health datasets based on the 'moa' column.\n",
    "common_key = 'soa'\n",
    "hack_data = hack_data.merge(health_data, on=common_key, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the holdout dataset.\n",
    "holdout = pd.read_csv(data_location + \"holdout.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if holdout set shares the same columns as the hack_data dataset.\n",
    "shared_col_names = np.intersect1d(np.asarray(list(holdout)), np.asarray(list(hack_data)))\n",
    "holdout_list = [col for col in holdout.columns  if col not in shared_col_names]\n",
    "holdout_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 'quarter_end' column can be droped from the holdout dataset.\n",
    "# While the 'record_id' column will be added the hack_data dataset. \n",
    "holdout = holdout.drop(['quarter_end'], 1)\n",
    "hack_data['record_id'] = list(range(hack_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The final training and testing datasets have now be created and will be renamed\n",
    "# to 'train' and 'test' respectively for simplicity. \n",
    "train = hack_data\n",
    "test = holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the train dataset.\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the test dataset.\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scatter plot to identify any clear outliers within the training dataset. \n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['All_usual_residents'], y = train['gp_cost_per_registered_patient'])\n",
    "plt.ylabel('gp_cost_per_registered_patient', fontsize=13)\n",
    "plt.xlabel('All_usual_residents', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the outliers from the training dataset (was not used in final submission).\n",
    "# train = train[(train['gp_cost_per_registered_patient']>7) & (train['gp_cost_per_registered_patient']<27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers of entries and columns within the training and testing datasets. \n",
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "# Save the 'record_id' column\n",
    "train_ID = train['record_id']\n",
    "test_ID = test['record_id']\n",
    "\n",
    "# Now drop the 'record_id' colum since it is not required for the prediction stage.\n",
    "train.drop(\"record_id\", axis = 1, inplace = True)\n",
    "test.drop(\"record_id\", axis = 1, inplace = True)\n",
    "\n",
    "# Check the data size after dropping the 'record_id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scatter plot to identify any clear outliers within the training dataset.\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['health_dep_disability_rank'], y = train['gp_cost_per_registered_patient'])\n",
    "plt.ylabel('gp_cost_per_registered_patient', fontsize=13)\n",
    "plt.xlabel('health_dep_disability_rank', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scatter plot to identify any clear outliers within the training dataset.\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x = train['all_residents'], y = train['gp_cost_per_registered_patient'])\n",
    "plt.ylabel('gp_cost_per_registered_patient', fontsize=13)\n",
    "plt.xlabel('all_residents', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Normality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for normality within the 'gp_cost_per_registered_patient' variable. \n",
    "\n",
    "sns.distplot(train['gp_cost_per_registered_patient'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['gp_cost_per_registered_patient'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "# Now plot the distribution of the output variable. \n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('gp_cost_per_registered_patient distribution')\n",
    "\n",
    "# Get also the QQ-plot of the output variable.\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['gp_cost_per_registered_patient'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 'gp_cost_per_registered_patient' variable as it stands appears to be normally distributed. \n",
    "# This is a good sign and therefore does not require any transformation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Values within the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training and testing datasets to check for missing values.\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.gp_cost_per_registered_patient.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['gp_cost_per_registered_patient'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'missing_data' dataframe as a reference to all the columns containing missing values. \n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a barplot for the 'missing_data' dataset. \n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=all_data_na.index, y=all_data_na)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix for the training dataset. \n",
    "corrmat = train.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the missing values with \"None\" for the categorical columns. \n",
    "missing_data_list = missing_data.index.tolist()\n",
    "missing_cat_data_list = [col for col in missing_data_list if all_data[col].dtype == 'O']\n",
    "for col in missing_cat_data_list:\n",
    "    all_data[col] = all_data[col].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of all the numeric columns containing missing values. \n",
    "missing_num_data_list = [col for col in missing_data_list if all_data[col].dtype == 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate the values within the missing numeric columns list into separate lists concerning the\n",
    "# original training datasets.\n",
    "missing_starter_num_data_list = [col for col in missing_num_data_list if col in starter_data.columns]\n",
    "missing_employment_num_data_list = [col for col in missing_num_data_list if col in employment_data.columns]\n",
    "missing_waiting_num_data_list = [col for col in missing_num_data_list if col in waiting_data.columns]\n",
    "missing_health_num_data_list = [col for col in missing_num_data_list if col in health_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now to systematically replace the missing values within the numeric columns with median column values. \n",
    "# These median values will be grouped by the common columns determined earlier.\n",
    "for col in missing_starter_num_data_list:\n",
    "    all_data[col] = all_data[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_employment_num_data_list:\n",
    "    all_data[col] = all_data.groupby(['soa'])[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_health_num_data_list:\n",
    "    all_data[col] = all_data.groupby(['soa'])[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_waiting_num_data_list:\n",
    "    all_data[col] = all_data.groupby(['hsc_trust', 'gp_month', 'gp_year'])[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_waiting_num_data_list:\n",
    "    all_data[col] = all_data.groupby(['gp_month', 'gp_year'])[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_waiting_num_data_list:\n",
    "    all_data[col] = all_data.groupby(['gp_year'])[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in missing_num_data_list:\n",
    "    all_data[col] = all_data[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there is any remaining missing values within the training and testing datasets. \n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Skewness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert numeric columns with less than 15 unique values to categorical variables. \n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "num_to_cat_columns = [col for col in numeric_feats if len(set(all_data[col])) < 15]\n",
    "for col in num_to_cat_columns:\n",
    "    all_data[col] = all_data[col].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Compute the skewness of all the numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the absolute skewness value for the numeric column is greater than 0.75 it will be Box-Cox transformed.\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index.tolist()\n",
    "# Remove 'longitude' variable from skewed_features dataset as it return extra NaN values. \n",
    "del skewed_features[skewed_features.index('longitude')]\n",
    "# Lambda value of 0.15:\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas get_dummies function to convert the categorical variables into dummy variables. \n",
    "all_data = pd.get_dummies(all_data)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally seperate the all_data dataset back into the training and testing datasets. \n",
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model Stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "# Create MSE function to be used for evaluation of the machine learning models. \n",
    "def mse_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    mse= -cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a Pipeline from the Lasso estimator.\n",
    "# Using the RobustScaler() function scales the features using statistics that are robust to outliers.\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a Pipeline from the ElasticNet estimator.\n",
    "# Using the RobustScaler() function scales the features using statistics that are robust to outliers.\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a KernelRidge estimator.\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a GradientBoostingRegressor estimator.\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.06,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=13, min_samples_split=17, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a XGBRegressor estimator.\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.3210, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.8105, reg_lambda=0.9052,\n",
    "                             subsample=0.14736, silent=1, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a LGBMRegressor estimator.\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=6,\n",
    "                              learning_rate=0.04, n_estimators=720,\n",
    "                              max_bin = 49, bagging_fraction = 0.17,\n",
    "                              bagging_freq = 8, feature_fraction = 0.2,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =9, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(lasso)\n",
    "print(\"\\nLasso MSE score: {:.4f} ({:.4f})\\n\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(ENet)\n",
    "print(\"ElasticNet MSE score: {:.4f} ({:.4f})\\n\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(KRR)\n",
    "print(\"Kernel Ridge MSE score: {:.4f} ({:.4f})\\n\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(GBoost)\n",
    "print(\"Gradient Boosting MSE score: {:.4f} ({:.4f})\\n\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(model_xgb)\n",
    "print(\"Xgboost MSE score: {:.4f} ({:.4f})\\n\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mse_cv(model_lgb)\n",
    "print(\"LGBM MSE score: {:.4f} ({:.4f})\\n\" .format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Stacked Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BaseEstimator object - Base class for all estimators in scikit-learn.\n",
    "# RegressorMixin object - Mixin class for all regression estimators in scikit-learn.\n",
    "# TransformerMixin object - Mixin class for all transformers in scikit-learn..\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        '''\n",
    "        base_models: A list of base models that will be stacked. \n",
    "        meta_model: A single model that will be used to stack the base models. \n",
    "        n_folds: The number of folds to be used in cross-validation. \n",
    "        '''\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Define a holder for the base_models. \n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        \n",
    "        # Define a KFold object used to determine the CV fold indexes. \n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Define a container for the predictions of each of the base models. \n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Train the meta-model on the out-of-fold predictions of the base models for the training dataset.\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    # Now use the trained meta model to predict the output using the predictions of the base models for \n",
    "    # the test dataset.\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "mse_score = mse_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models MSE score: {:.4f} ({:.4f})\".format(mse_score.mean(), mse_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(y, y_pred):\n",
    "    return mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = stacked_averaged_models.predict(test.values)\n",
    "print(mse(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['record_id'] = test_ID\n",
    "# sub['prediction'] = stacked_pred\n",
    "# sub.to_csv('stacked_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = model_xgb.predict(test)\n",
    "print(mse(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['record_id'] = test_ID\n",
    "# sub['prediction'] = xgb_pred\n",
    "# sub.to_csv('xgb_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = model_lgb.predict(test.values)\n",
    "print(mse(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame()\n",
    "# sub['record_id'] = test_ID\n",
    "# sub['prediction'] = lgb_pred\n",
    "# sub.to_csv('lgb_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Final Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predistions_df = pd.DataFrame({\n",
    "    'stacked':stacked_train_pred,\n",
    "    'xgb':xgb_train_pred,\n",
    "    'lgb':lgb_train_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit (predistions_df.values, y_train)\n",
    "coefs = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE score on train data:')\n",
    "print(mse(y_train,stacked_train_pred*coefs[0] +\n",
    "               xgb_train_pred*coefs[1] + lgb_train_pred*coefs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predistions_df = pd.DataFrame({\n",
    "    'stacked':stacked_pred,\n",
    "    'xgb':xgb_pred,\n",
    "    'lgb':lgb_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*coefs[0] + xgb_pred*coefs[1] + lgb_pred*coefs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['record_id'] = test_ID\n",
    "sub['prediction'] = ensemble\n",
    "sub.to_csv('lin_reg_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.8105, reg_lambda=0.9052,\n",
    "                             subsample=0.14736, silent=1, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb.fit(predistions_df, y_train)\n",
    "xgb_train_pred_ensemble = model_xgb.predict(predistions_df)\n",
    "xgb_pred_ensemble = model_xgb.predict(test_predistions_df)\n",
    "print(mse(y_train, xgb_train_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['record_id'] = test_ID\n",
    "sub['prediction'] = xgb_pred_ensemble\n",
    "sub.to_csv('final_sub.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
